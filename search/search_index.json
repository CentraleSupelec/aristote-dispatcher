{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pr\u00e9sentation","text":""},{"location":"#aristote-dispatcher","title":"Aristote Dispatcher","text":"<p>Aristote Dispatcher permet :</p> <ul> <li>le d\u00e9ploiement \u00e0 grande \u00e9chelle de LLM,</li> <li>l'optimisation de l'utilisation de vos GPUs,</li> <li>la priorisation des t\u00e2ches importantes.</li> </ul> <p>En bref, avec Aristote Dispatcher :</p> <ul> <li>vous garantissez que vos GPUs sont avant tout utilis\u00e9s pour leurs t\u00e2ches principales</li> <li>vous leur permettez de travailler sur des t\u00e2ches secondaires,</li> <li>vous assurez \u00e0 l'utilisateur une API transparente suivant les standards Open AI.</li> </ul> <p>Aristote Dispatcher est utilis\u00e9 en production \u00e0 CentraleSup\u00e9lec depuis 2024 pour permettre l'utilisation de GPUs sur des LLM lorsqu'il ne sont pas utilis\u00e9s par Aristote.</p>"},{"location":"#architecture","title":"Architecture","text":"Architecture d'Aristote Dispatcher <p>Son architecture permet de passer \u00e0 l'\u00e9chelle en fonction de la demande, des besoins et du nombre de GPUs disponibles.</p> <p>Sa modularit\u00e9 permet un monitoring pr\u00e9cis des diff\u00e9rents composants en utilisant Prometheus et une r\u00e9solution simple de la majorit\u00e9 des probl\u00e8mes : troubleshooting</p>"},{"location":"#confidentialite","title":"Confidentialit\u00e9","text":"<p>Enfin, Aristote Dispatcher est respectueux des donn\u00e9es des utilisateurs puisque vous conservez en permanence la ma\u00eetrise des donn\u00e9es qui y transitent.</p> <p>Acc\u00e8s au code source Contactez-nous</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>Les capacit\u00e9s de Kubernetes et des modules d\u00e9ploy\u00e9s permettent de r\u00e9soudre automatiquement des probl\u00e8mes courants.</p> <p>Monitorer Aristote Dispatcher permet toutefois de v\u00e9rifier en permanence l'\u00e9tat du cluster, en particulier en cas de probl\u00e8me plus profond, non r\u00e9solu automatiquement.</p>"},{"location":"troubleshooting/#senders","title":"Senders","text":"<ul> <li>Le nombre de senders fluctue</li> </ul> <p>Ceci signifie que la connexion \u00e0 la base de donn\u00e9es ou \u00e0 RabbitMQ ne s'effectue pas correctement. Les logs permettent d'obtenir plus d'informations.</p> <p>Dans le premier cas, elle est soit injoignable soit corrompue. Dans le second, le cluster RabbitMQ est peut-\u00eatre d\u00e9t\u00e9rior\u00e9.</p>"},{"location":"troubleshooting/#consumers","title":"Consumers","text":"<ul> <li>Le nombre de consumers fluctue</li> </ul> <p>Ceci signifie que la connexion \u00e0 RabbitMQ ne s'effectue pas correctement. Les logs permettent d'obtenir plus d'informations.</p> <p>Le cluster RabbitMQ est peut-\u00eatre d\u00e9t\u00e9rior\u00e9.</p> <ul> <li>Un consumer red\u00e9marre en boucle de mani\u00e8re p\u00e9riodique</li> </ul> <p>Ceci signifique que la connexion \u00e0 vLLM ne s'effectue pas correctement. Les logs permettent d'obtenir plus d'informations.</p> <p>vLLM a probablement des difficult\u00e9s \u00e0 d\u00e9marrer : carte graphique indisponible, mod\u00e8le indisponible, ...</p>"},{"location":"troubleshooting/#rabbitmq","title":"RabbitMQ","text":"<ul> <li>Le cluster semble d\u00e9t\u00e9rior\u00e9</li> </ul> <p>Il faut identifier le ou les noeuds probl\u00e9matiques, et les red\u00e9marrer. Si votre monitoring le permet, inspecter l'\u00e9tat des queues permet de d\u00e9terminer quels noeuds sont en retard (les moins remplis).</p> <ul> <li>Le nombre de queues est trop petit</li> </ul> <p>En fonctionnement normal, le nombre de queue doit \u00eatre \u00e9gal \u00e0 la somme du nombre de senders et du nombre de mod\u00e8les diff\u00e9rents. S'il y a un probl\u00e8me, inspecter l'\u00e9tat des queues ou red\u00e9marrer les consumers (sans danger) permettra de r\u00e9soudre le probl\u00e8me.</p>"},{"location":"troubleshooting/#vllm","title":"vLLM","text":"<ul> <li>La latence est trop \u00e9lev\u00e9e</li> </ul> <p>Cela signifie que les cartes graphiques re\u00e7oivent plus de demandes qu'elles ne peuvent traiter. Il faut alors augmenter le nombre de cartes graphiques sur votre cluster.</p>"}]}